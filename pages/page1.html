<!DOCTYPE HTML>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="../css/styles.css">
    <title>Controverse I.A.</title>
</head>
<body>
    <header id="top">
        <h1><a href="../page.html"><strong>Intelligences Artificielles</strong></a></h1>
        <nav>
            <blockquote id="question">Les I.A. sont elles vraiment intelligentes?</blockquote>
            <div class="button">
                <a href="../page.html">Accueil</a>
            </div>
            <div class="button">
                <a href="">Pages</a>
                <div class="submenu">
                    <div><a href="page1.html" class="sub">Page 1</a></div>
                    <div><a href="page2.html" class="sub">Page 2</a></div>
                    <div><a href="page3.html" class="sub">Page 3</a></div>
                    <div><a href="page4.html" class="sub">Page 4</a></div>
                </div>
            </div>
            <div class="button">
                <a href="contact.html">Contacts</a>
            </div>
            <div id="burger">
                <svg width="34px" height="27px">
                    <rect width="34px" height="4px"/>
                    <rect y="11" width="34px" height="4px"/>
                    <rect y="23" width="34px" height="4px"/>
                </svg>
                <div id="b_submenu">
                    <div>
                        <a href="../page.html">Accueil</a>
                    </div>
                    <div>
                        <a href="contact.html">Contacts</a>
                    </div>
                    <div>
                        <a href="" class="sub">Pages</a>
                        <div id="b_subpages">
                            <a href="page1.html" class="sub">Page 1</a>
                            <a href="page2.html" class="sub">Page 2</a>
                            <a href="page3.html" class="sub">Page 3</a>
                            <a href="page4.html" class="sub">Page 4</a>
                        </div>
                    </div>
                </div>
            </div>
        </nav>
    </header>
    <main>
        <h2>Chronologie et Fonctionnement</h2>
        <article>
            <p>
                Pour comprendre d’où viens cette question et comment avoir des éléments de réponses, il faut tout d’abord savoir d’où viennent les IA, comment sont-elles nées et les différentes parties de leur évolution qui les ont mené la où elles sont aujourd’hui.
            </p><p>
                <h3>Dartmouth Workshop 1956 : la naissance de l'IA</h3> En 1956, la conférence de Dartmouth a été organisée par Marvin Minsky, John McCarthy et deux scientifiques principaux d'IBM : Claude Shannon et Nathan Rochester. "Une machine peut être construite pour dupliquer n'importe quel aspect de l'intelligence humaine", indique la proposition. Les participants comprenaient Ray Solomonoff, Oliver Selfridge, Trenchard More, Arthur Samuel, Allen Newell et Herbert A. Simon, qui ont tous continué à créer d'importants projets d'IA au cours des premières décennies d'études. Lors de la conférence, Newell et Simon ont dévoilé le "théoricien de la logique" tandis que McCarthy a exhorté les participants à accepter "l'intelligence artificielle" comme nom de leur domaine. La conférence de Dartmouth de 1956 a été l'événement qui a donné à l'IA son nom, son objectif et son premier succès, ainsi que ses acteurs clés et ses moments déterminants.
            <p>
                <h3>IA symbolique 1956–1974 </h3> Pour la plupart des gens, les années qui ont suivi l'atelier de Dartmouth étaient tout simplement « stupéfiantes » : les ordinateurs résolvaient des problèmes d'algèbre, prouvaient des théorèmes géométriques et apprenaient à parler anglais. À la fin des années 1960, peu de gens auraient pensé qu'un tel comportement "intelligent" des machines était concevable. En privé et sur papier, les universitaires ont exprimé leur grand optimisme quant à la mise au point d'une machine pleinement intelligente en moins de 20 ans. Le nouveau domaine a attiré un financement important d'agences gouvernementales comme la DARPA.
            <p>
                <h3>Le premier hiver AI 1974-1980 </h3>Dans les années 1970, l'IA a fait face à des critiques et à des revers financiers. Les difficultés auxquelles les chercheurs en IA étaient confrontés n'étaient pas reconnues par eux. Leurs énormes attentes avaient été élevées bien au-delà de ce qui était raisonnable, et lorsque les avantages promis ne se sont pas concrétisés, le financement gouvernemental pour l'IA a disparu. Dans le même temps, pendant dix ans après la critique dévastatrice des perceptrons par Marvin Minsky, le domaine du connexionnisme (ou réseaux de neurones) est resté en sommeil. Malgré la vision négative du public sur l'IA à la fin des années 1970, de nouvelles idées ont été explorées dans la programmation logique, le raisonnement de bon sens et une variété d'autres domaines.
            <p>
                <h3>Boum 1980–1987 </h3>Dès les premiers jours de l'IA, la connaissance était une préoccupation majeure. Les systèmes experts, une forme de programme d'IA, ont été adoptés par des entreprises du monde entier dans les années 1980 et la connaissance est devenue le centre de la recherche principale sur l'IA. Dans les années 1990, le gouvernement japonais a fortement investi dans l'IA avec son initiative informatique de cinquième génération. La résurgence du connexionnisme dans les œuvres de John Hopfield et David Rumelhart au début des années 1980 a été un autre moment encourageant. Encore une fois, l'IA avait réussi.
            <p>
                <h3>IA 1993–2011 </h3>Le domaine de l'intelligence artificielle, qui a plus d'un demi-siècle, a atteint certains de ses objectifs les plus élémentaires. Il est actuellement utilisé efficacement dans tout le secteur de la technologie, bien qu'un peu discrètement. Certaines d'entre elles résultaient de l'amélioration des capacités informatiques, tandis que d'autres résultaient de la concentration sur des problèmes spécifiques isolés et de la volonté d'atteindre les plus hauts niveaux de responsabilité scientifique. Et pourtant, la réputation de l'IA dans le monde des affaires était moins que stellaire. Dans le domaine, il y avait peu d'accord sur les raisons pour lesquelles l'IA n'avait pas pu tenir sa promesse d'intelligence au niveau humain dans les années 1960. L'IA a été scindée en un certain nombre de disciplines distinctes, chacune se concentrant sur un problème ou une méthode différente, tout en donnant néanmoins l'illusion qu'elles travaillaient vers le même objectif.
            <p>
                Maintenant que nous savons d’où elles viennent, il faut comprendre le côté technique de ces intelligences artificielles, comment marchent-elles ? 
            <p>
                <h3>Le Machine Learning </h3>ou apprentissage automatique est un domaine scientifique, et plus particulièrement une sous-catégorie de l’intelligence artificielle. Elle consiste à laisser des algorithmes découvrir des  «  patterns » dans les ensembles de données. Ces données peuvent être des chiffres, des mots, des images, des statistiques…
            <p>
                Tout ce qui peut être stocké numériquement peut servir de données pour le Machine Learning. En décelant les patterns dans ces données, les algorithmes apprennent et améliorent leurs performances dans l’exécution d’une tâche spécifique.
            <p>
                Pour résumer, les algorithmes de Machine Learning apprennent de manière autonome à effectuer une tâche ou à réaliser des prédictions à partir de données et améliorent leurs performances au fil du temps. Une fois entraîné, l’algorithme pourra retrouver les patterns dans de nouvelles données. Le développement d’un modèle de Machine Learning repose sur quatre étapes principales.
            <ol>
                <li>La première étape consiste à sélectionner et à préparer un ensemble de données d’entraînement. Ces données seront utilisées pour nourrir le modèle de Machine Learning pour apprendre à résoudre le problème pour lequel il est conçu. Les données doivent être soigneusement préparées, organisées et nettoyées. Dans le cas contraire, l’entraînement du modèle de Machine Learning risque d’être biaisé. Les résultats de ses futures prédictions seront directement impactés.</li>
                <li>La deuxième étape consiste à sélectionner un algorithme à exécuter sur l’ensemble de données d’entraînement. Le type d’algorithme à utiliser dépend du type et du volume de données d’entraînement et du type de problème à résoudre.</li>
                <li>La troisième étape est l’entraînement de l’algorithme. Des variables sont exécutées à travers l’algorithme, et les résultats sont comparés avec ceux qu’il aurait du produire. On exécute ensuite de nouveau les variables jusqu’à ce que l’algorithme produise le résultat correct la plupart du temps. L’algorithme représente  le modèle de Machine Learning.</li>
                <li>La quatrième et dernière étape est l’utilisation et l’amélioration du modèle. On utilise le modèle sur de nouvelles données, dont la provenance dépend du problème à résoudre. Par exemple, un modèle de Machine Learning conçu pour détecter les spam sera utilisé sur des emails. L’efficacité et la précision peuvent également s’accroître au fil du temps.</li>
            </ol><p>
                <h3>On distingue trois techniques de Machine Learning : l’apprentissage supervisé, l’apprentissage non-supervisé, et l’apprentissage par renforcement.</h3>
            <p>
                Dans le cas de l’apprentissage supervisé, le plus courant, les données sont étiquetées afin d’indiquer à la machine quelles patterns elle doit rechercher.Le système s’entraîne sur un ensemble de données étiquetées, avec les informations qu’il est censé déterminer. Les données peuvent même être déjà classifiées de la manière dont le système est supposé le faire.Cette méthode nécessite moins de données d’entraînement que les autres, et facilite le processus d’entraînement puisque les résultats du modèle peuvent être comparés avec les données déjà étiquetées. Cependant, l’étiquetage des données peut se révéler onéreux. Un modèle peut aussi être biaisé à cause des données d’entraînement, ce qui impactera ses performances par la suite lors du traitement de nouvelles données.
            <p>
                Au contraire, dans le cas de l’apprentissage non supervisé, les données n’ont pas d’étiquettes. La machine se contente d’explorer les données à la recherche d’éventuelles patterns. Elle ingère de vastes quantités de données, et utilise des algorithmes pour en extraire des caractéristiques pertinentes requises pour étiqueter, trier et classifier les données en temps réel sans intervention humaine.Plutôt que d’automatiser les décisions et les prédictions, cette approche permet d’identifier les patterns et les relations que les humains risquent de ne pas identifier dans les données. Cette technique n’est pas très populaire, car moins simple à appliquer. Elle est toutefois de plus en plus populaire dans le domaine de la cyber sécurité.
            </p><p>
                Enfin, l’apprentissage par renforcement consiste à laisser un algorithme apprendre de ses erreurs pour atteindre un objectif. L’algorithme essayera de nombreuses approches différentes pour tenter d’atteindre son but.En fonction de ses performances, il sera récompensé ou pénalisé pour l’inciter à poursuivre dans une voie ou à changer d’approche. Cette technique est notamment utilisée pour permettre à une IA de surpasser les humains dans les jeux. Par exemple, AlphaGo de Google a battu le champion de Go grâce à l’apprentissage par renforcement. De même, OpenAI a entraîné une IA capable de vaincre les meilleurs joueurs du jeu vidéo Dota 2.
            </p><p>
                <h3>Après tout cela, on sait qu’il existe trois types d’IA :</h3>   
            <ul>
                <li>L’intelligence artificielle étroite (ANI), qui possède une gamme étroite de capacités</li>
                <li>L’intelligence artificielle générale (AGI), qui est à la hauteur des capacités humaines</li>
                <li>La super intelligence artificielle (ASI), dont les capacités sont supérieures à celles de l’homme</li>
            </ul>
            <p>
                Seulement deux d’entre elles existe et la dernière cité n’est qu’hypothétique, c’est elle qu’on retrouvera souvent dans les films hollywoodien. Elle est celle imaginé quand on dit que les machines vont un jour dépasser et remplacer l’Homme.
            </p>
            <h3>Bibliographie</h3>
            <p>
                X. De La Porte, « Pour un internet bête - une critique de l’intelligence en informatique »,Lundi 31 janvier 2022 [En ligne]. Disponible sur: <a class="bibli" href="https://www.radiofrance.fr/franceinter/podcasts/le-code-a-change/pour-un-internet-bete-une-critique-de-l-intelligence-en-informatique-7688523">https://www.radiofrance.fr/...</a>
            </p>
            <p>
                J. Guinamard, « Quel futur pour l’IA et le deep learning? », Siècle Digital, 9 juillet 2021. <a class="bibli" href="https://siecledigital.fr/2021/07/09/futur-ia-deep-learning/">https://siecledigital.fr/...</a>
            </p>
        </article>
        <a href="#top"><img alt="flèche" src="../images/fleche.png" id="gotop"></a>
    </main>
    <footer>
        <div><p>Vous avez relevé des bugs?</p><a href="../pages/contact.html">Contactez nous ! </a></div>
        <div><p>Ce site est sponsorisé par © Sony</p><p>Tous droits réservés</p></div>
        <div><p>Vous voulez en savoir plus sur l'Intelligence Artificielle? </p><a href="https://fr.wikipedia.org/wiki/Intelligence_artificielle">c'est est ici que ça se passe</a></div>
    </footer>
</body>
</html>
